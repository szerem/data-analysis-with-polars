{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea3afa8a-0219-494a-8f03-12a21d8223de",
   "metadata": {},
   "source": [
    "# Polars quickstart\n",
    " \n",
    "To help you get started this notebook introduces some of the key concepts that make Polars a powerful data analysis tool.\n",
    "\n",
    "The key concepts we meet are:\n",
    "- fast flexible analysis with the Expression API in Polars\n",
    "- easy parallel computations\n",
    "- automatic query optimisation in lazy mode\n",
    "- streaming to work with larger-than-memory datasets in Polars\n",
    "\n",
    "## Stay in touch\n",
    "I post a lot of material about Polars on social media and my blog. Stay in touch by\n",
    "- connecting with me on LinkedIn https://www.linkedin.com/in/liam-brannigan-9080b214a/\n",
    "- following me on twitter https://twitter.com/braaannigan\n",
    "- check out my blog posts https://www.rhosignal.com/\n",
    "- see my youtube channel https://www.youtube.com/channel/UC-J3uR0g7CxCSnx0YFE6R_g/\n",
    "\n",
    "Send a message to say hi if you are coming from the course! \n",
    "\n",
    "## Importing Polars\n",
    "We begin by importing polars as `pl`. Following this convention will allow you to work with examples from the official documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad810bd3-f454-48b7-9af9-363514fa4176",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import polars as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa74a155-9f01-4d37-9d7a-83f6889ac7f7",
   "metadata": {},
   "source": [
    "## Setting configuration options\n",
    "We want to control how many rows of a `DataFrame` are printed out to the screen. Polars allows us to control configuration using options using methods in the `pl.Config` namespace.\n",
    "\n",
    "In this notebook we want Polars to print 6 rows of `DataFrame` so we use `pl.Config.set_tbl_rows`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1cf030-ca90-4ccb-b102-6f7d2dac6690",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pl.Config.set_tbl_rows(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4c2ff6-4c50-4002-bd07-cb66c6c89e4b",
   "metadata": {},
   "source": [
    "You can see the full range of configuration options here: https://pola-rs.github.io/polars/py-polars/html/reference/config.html\n",
    "\n",
    "In the course we see how to apply the right configuration options in a range of contexts.\n",
    "\n",
    "## Input data\n",
    "Polars can read from a wide range of data formats including CSV, Parquet, Arrow, JSON, Excel and database connections. We cover all of these in the course.\n",
    "\n",
    "For this introduction we use a CSV with the Titanic passenger dataset. This dataset gives details of all the passengers on the Titanic and whether they survived.\n",
    "\n",
    "We begin by setting the path to this CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195ea4e6-dbef-4a3e-b2da-0dd7c84a6816",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "csv_file = \"../data/titanic.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e0973f-d2ba-4c29-9ecb-2b7b1d58bee8",
   "metadata": {},
   "source": [
    "We read the CSV into a Polars `DataFrame` with the `read_csv` function. \n",
    "\n",
    "We then call `head` to print out the first few rows of the `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0407fc1-e41e-4613-9163-56f9daf68d47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pl.read_csv(csv_file)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f97603-768a-459c-a1c9-11bbd741bc43",
   "metadata": {},
   "source": [
    "Each row of the `DataFrame` has details about a passenger on the Titanic including the class they travelled in (`Pclass`), their name (`Name`) and `Age`.\n",
    "\n",
    "Alternatively we can use `glimpse` to see the first data points arranged vertically. I use this regularly for dataframes with a lot of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4416a4-86f8-4c7f-ab63-8749f31afff9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(df.glimpse())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd37b789-901d-4259-af96-5a05b732e005",
   "metadata": {},
   "source": [
    "## Expressions\n",
    "You can use square brackets to select rows and columns in Polars..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1452e27-d791-4852-bd53-220fef08a03f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[:3,[\"Pclass\",\"Name\",\"Age\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecd56c7-e764-4218-bc72-66fe206f54df",
   "metadata": {},
   "source": [
    "...but using this square bracket approach means that you don't get all the benefits of parallelisation and query optimisation.\n",
    "\n",
    "> We learn more about square bracket indexing in Section 3 of the course.\n",
    "\n",
    "To really take advantage of Polars we use the Expression API.\n",
    "\n",
    "### Selecting and transforming columns with the Expression API\n",
    "\n",
    "We see a simple example of the Expression API here where we select the `Pclass`, `Name` and `Age` columns inside a `select` statement (we learn much more about a `select` statement in Section 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b12f502-21dc-435d-917d-fcd0ccbef8a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(\n",
    "    df\n",
    "    .select(\n",
    "        [\n",
    "            pl.col(\"Pclass\"),\n",
    "            pl.col(\"Name\"),\n",
    "            pl.col(\"Age\"),\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f62842e-c598-4a45-ae91-3466a3dc5258",
   "metadata": {},
   "source": [
    "In the Expression API we use `pl.col` to refer to a column.\n",
    "\n",
    "We would like the strings in the `Name` column to be printed wider. We can do this with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63963cab-16e7-419a-94af-fe0a99e278ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.Config.set_fmt_str_lengths(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64d267f-7573-4a50-b90f-9eb6d5e67305",
   "metadata": {},
   "source": [
    "> We learn more about the `pl.Config` namespace for configuring how Polars looks and behaves in a lecture later in this Section.\n",
    "\n",
    "### What is an expression?\n",
    "\n",
    "An expression is a function that takes a `Series` (or column in a `DataFrame`) in and returns `Series` (or column in a `DataFrame`). \n",
    "\n",
    "Expressions are the core building blocks of data transformations and include:\n",
    "- the identity expression where the output is the same as the input\n",
    "- arithmetic where we add/multiply/etc all elements of a `Series`\n",
    "- rounding off all elements of a `Series`\n",
    "- converting all strings in a `Series` to uppercase\n",
    "- extracting the date from all elements of a datetime `Series`\n",
    "- and so on\n",
    "\n",
    "In this example we select the same three columns, but this time we:\n",
    "- convert the names to lowercase and\n",
    "- round off the age to 2 decimal places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d3207c-fcd7-46d5-a8f1-bb7057c54bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df\n",
    "    .select(\n",
    "        [\n",
    "            # Identity expression\n",
    "            pl.col(\"Pclass\"),\n",
    "            # Names to lowercase\n",
    "            pl.col(\"Name\").str.to_lowercase(),\n",
    "            # Round the ages\n",
    "            pl.col(\"Age\").round(2)\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5678a86d-8762-43ad-b054-9f5775d5b03a",
   "metadata": {},
   "source": [
    "When we have multiple expressions like this Polars runs them in parallel.\n",
    "\n",
    "Expressions can also return a shorter `Series` such as `head` to return the first rows or aggregating expressions such as `mean` to get the average of the values in a `Series`. Expressions can also return a longer `Series` such as `explode` that converts a list `Series` to individual rows.\n",
    "\n",
    "> We learn much more about expressions in Section 3 of the course.\n",
    "\n",
    "### Method chaining and code formatting\n",
    "In the cell above the code is wrapped in parantheses `()`. In Python (rather than Polars in particular) when we wrap code in parantheses we can call a new method - in this case `select` - on a new line.\n",
    "\n",
    "In Polars we often build queries in multiple steps with multiple calls to new methods. I find it is much easier to read a series of queries if each method starts on a new line so I will generally wrap code blocks in paranetheses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19199543-fb56-40d8-ad59-c9edba58ab96",
   "metadata": {},
   "source": [
    "### Expression chaining\n",
    "\n",
    "As well as chaining methods we can chain expressions together to do more transformations in a single step. \n",
    "\n",
    "In this example we return three columns:\n",
    "- the original `Name` columns\n",
    "- the `Name` column split into a list of words\n",
    "- the count of the number of words when the `Name` column split into a list of words\n",
    "\n",
    "Column names in a Polars `DataFrame` are always strings and must be unique. We use the `alias` method at the end of the second and third expressions so we do not end up with multiple columns called `Name`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98151ca-ea98-47ea-b6af-26c56538591d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(\n",
    "    df\n",
    "    .select(\n",
    "        [\n",
    "            # Get the Name column without changes\n",
    "            pl.col(\"Name\"),\n",
    "            # Take the Name column and split it into a list of separate words\n",
    "            pl.col(\"Name\").str.split(\" \").alias(\"Name_split\"),\n",
    "            # Take the Name column, split it into a list of separate words and count the number of words\n",
    "            pl.col(\"Name\").str.split(\" \").list.len().alias(\"Name_word_count\"),\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2deb94-42e2-453a-938c-9aa0e0932682",
   "metadata": {},
   "source": [
    "We look at expressions in detail throughout the course to find the right expression for many different scenarios.\n",
    "\n",
    "Expressions can seem verbose, but they also allow us to select groups of columns in one go. For example, to select all the integer columns we can use `pl."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37606301-202f-45ce-a056-58c477fb1e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df\n",
    "    .select(\n",
    "        pl.col(pl.INTEGER_DTYPES)\n",
    "    )\n",
    "    .head(3)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444797f2-1fb4-449f-a364-a54af93386d8",
   "metadata": {},
   "source": [
    "> We meet other ways to quickly select multiple columns in Section 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4f45a3-0862-4ca5-8af8-81e9b9fdf2b0",
   "metadata": {},
   "source": [
    "### Filtering a `DataFrame` with the Expression API\n",
    "\n",
    "We filter a `DataFrame` by applying a condition to an expression.\n",
    "\n",
    "In this example we find all the passengers over 70 years of age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ce72f9-3a9c-4cba-9010-c46894316463",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(\n",
    "    df\n",
    "    .filter(\n",
    "        pl.col(\"Age\") > 70\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015f274a-69d7-4215-9ffa-0784bc53dd66",
   "metadata": {},
   "source": [
    "We are not limited to using the Expression API for these operations. The Expression API is at the heart of all data transformations in Polars as we see below.\n",
    "\n",
    "> We learn more about applying filter conditions in Section 2 of the course."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7887c01d-29e1-4871-bb4d-b5499fecd234",
   "metadata": {},
   "source": [
    "## Analytics\n",
    "Polars has a wide range of functionality for analysing data. In the course we look at a wider range of analytic methods and how we can use expressions to write more complicated analysis in a concise way.\n",
    "\n",
    "We begin by getting an overview of the `DataFrame` with `describe`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574a41d3-be19-446c-829b-bc85f5385312",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d556f10c-48e8-4355-880f-eedf640b217e",
   "metadata": {},
   "source": [
    "The output of `describe` shows us how many records there are, how many `null` values and some key statistics. The `null_count` has helped me identify emerging data quality issues in my machine learning pipelines.\n",
    "\n",
    "### Value counts on a column\n",
    "We use `value_counts` to count occurences of values in a column.\n",
    "\n",
    "In this example we count how many passengers there are in each class with `value_counts`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa1e191-8e7c-4c9b-83e5-ea0f7416141f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[\"Pclass\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe37f31-28de-4b82-934e-d698996084a4",
   "metadata": {},
   "source": [
    "### Groupby and aggregations\n",
    "Polars has a fast parallel algorithm for `group_by` operations. \n",
    "\n",
    "Here we first group by the `Survived` and the `Pclass` columns. We then aggregate in `agg` by counting the number of passengers in each group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72992a3d-5120-4a84-96c2-bed07d079677",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(\n",
    "    df\n",
    "    .group_by([\"Survived\",\"Pclass\"])\n",
    "    .agg(\n",
    "        pl.col(\"PassengerId\").count().alias(\"count\")\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e5b21f-a7c7-4aa5-b19d-74a24bd47805",
   "metadata": {},
   "source": [
    "We use the Expression API to for each aggregation in `agg`.\n",
    "\n",
    "Groupby operations in Polars are fast because Polars has a parallel algorithm for getting the groupby keys. Aggregations are also fast because Polars runs multiple expressions in `agg` in parallel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6654a50d-ec2e-4d56-9ab4-c58e21784ff6",
   "metadata": {},
   "source": [
    "### Window operations\n",
    "Window operations occur when we want to add a column that reflects not just data from that row but from a related group of rows. Windows occur in many contexts including rolling or temporal statistics and Polars covers these use cases.\n",
    "\n",
    "Another example of a window operation is when we want on each row to have a statistic for a group of rows. We use the `over` expression for this (equivalent to `groupby-transform` in Pandas).\n",
    "\n",
    "In this example we are going to add a column with the maximum age of the passenger in each class. To add a column we use an expression inside the `with_columns` method (we see much more of this method in Section 2). In the expression we calculate the maximum `Age` and specify that we want here we use `over` to calculate that max by the passenger class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c43604-3175-4f98-a7e0-7aaa9a099573",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df\n",
    "    .with_columns(\n",
    "        pl.col(\"Age\").max().over(\"Pclass\").alias(\"MaxAge\")\n",
    "    )\n",
    "    .select(\"Pclass\",\"Age\",\"MaxAge\")\n",
    "    .head(3)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b68918e-5b0b-40d8-8cf9-ca5f4077afd8",
   "metadata": {},
   "source": [
    "> We learn more about grouping and aggregations in Section 4 of the course.\n",
    "\n",
    "### Visualisation\n",
    "\n",
    "We can use popular plotting libraries like Matplotlib, Seaborn, Altair and Plotly directly with Polars.\n",
    "\n",
    "In this example we create a scatter plot of bar chart of age and fare with Altair (version 5+ of Altair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c73536-dbd9-47a3-8ad4-aa7bfe4e9f99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "alt.Chart(\n",
    "    df,\n",
    "    title=\"Scatter plot of Age and Fare\"\n",
    ").mark_circle().encode(\n",
    "    x=\"Age:Q\",\n",
    "    y=\"Fare:Q\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b9824c-1bcd-486c-b3ac-151d9e5f833a",
   "metadata": {},
   "source": [
    "> We see how to work with Matplotlib, Seaborn, Altair and Plotly in the visualisation lecture in this Section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e18862c-208f-4f65-9bcf-5d75163551e7",
   "metadata": {},
   "source": [
    "## Lazy mode and query optimisation\n",
    "In the examples above we work in eager mode. In eager mode Polars runs each part of a query step-by-step.\n",
    "\n",
    "Polars has a powerful feature called lazy mode. In this mode Polars looks at a query as a whole to make a query graph. Before running the query Polars passes the query graph through its query optimiser to see if there ways to make the query faster.\n",
    "\n",
    "When working with a CSV we can switch from eager mode to eager mode by replacing `read_csv` with `scan_csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82853451-8a88-45b4-9c8b-04ab3d7a9bf3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(\n",
    "    pl.scan_csv(csv_file)\n",
    "    .group_by([\"Survived\",\"Pclass\"])\n",
    "    .agg(\n",
    "        pl.col(\"PassengerId\").count().alias(\"count\")\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ff7291-9daf-43ba-860e-d20bd6276625",
   "metadata": {},
   "source": [
    "The output of a lazy query is `LazyFrame` and we see the unoptimized query plan when we output a `LazyFrame`.\n",
    "\n",
    "### Query optimiser\n",
    "We can see the optimised query plan that Polars will actually run by add `explain` at the end of the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f31781-c8b8-474b-878f-dc16ef666b60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\n",
    "    pl.scan_csv(csv_file)\n",
    "    .group_by([\"Survived\",\"Pclass\"])\n",
    "    .agg(\n",
    "        pl.col(\"PassengerId\").count().alias(\"count\")\n",
    "    )\n",
    "    .explain()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed924f1-854a-4fcc-bdc4-72fb8b96f6bc",
   "metadata": {},
   "source": [
    "In this example Polars has identified an optimisation:\n",
    "```python\n",
    "PROJECT 3/12 COLUMNS\n",
    "```\n",
    "There are 12 columns in the CSV, but the query optimiser sees that only 3 of these columns are required for the query. When the query is evaluated Polars will `PROJECT` 3 out of 12 columns: Polars will only read the 3 required columns from the CSV. This projection saves memory and computation time.\n",
    "\n",
    "A different optimisation happens when we apply a `filter` to a query. In this case we want the same analysis of survival by class but only for passengers over 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ac2d16-8afc-442a-ad7c-e3a776a22b1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\n",
    "    pl.scan_csv(csv_file)\n",
    "    .filter(pl.col(\"Age\") > 50)\n",
    "    .group_by([\"Survived\",\"Pclass\"])\n",
    "    .agg(\n",
    "        pl.col(\"PassengerId\").count().alias(\"count\")\n",
    "    )\n",
    "    .explain()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdcb136-ce68-41af-8e83-60bdc9db1d57",
   "metadata": {},
   "source": [
    "In this example the query optimiser has seen that:\n",
    "- 4 out of 12 columns are now required `PROJECT 4/12 COLUMNS` and\n",
    "- only passengers over 50 should be selected `FILTER: [(col(\"Age\")) > (50.0)]`\n",
    "\n",
    "These optimisations are applied as Polars reads the CSV file so the whole dataset must not be read into memory.\n",
    "\n",
    "### Query evaluation\n",
    "\n",
    "To evaluate the full query and output a `DataFrame` we call `collect` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1580184-5e2e-4aae-84f8-b22ff42e0fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    pl.scan_csv(csv_file)\n",
    "    .filter(pl.col(\"Age\") > 50)\n",
    "    .group_by([\"Survived\",\"Pclass\"])\n",
    "    .agg(\n",
    "        pl.col(\"PassengerId\").count().alias(\"count\")\n",
    "    )\n",
    "    .collect()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6393e67-d572-4e92-b975-07524215e94b",
   "metadata": {},
   "source": [
    "We learn more about lazy mode and evaluating queries in this section of the course."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef8e7cc-bbd1-4aa2-baec-0e73fd4b1a2e",
   "metadata": {},
   "source": [
    "## Streaming larger-than-memory datasets\n",
    "By default Polars reads your full dataset into memory when evaluating a lazy query. However, if your dataset is too large to fit into memory Polars can run many operations in *streaming* mode. With streaming Polars processes your query in batches rather than all at once.\n",
    "\n",
    "To enable streaming we pass the `streaming = True` argument to `collect`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11add235-2654-438c-b795-9dc53e5114d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    pl.scan_csv(csv_file)\n",
    "    .filter(pl.col(\"Age\") > 50)\n",
    "    .group_by([\"Survived\",\"Pclass\"])\n",
    "    .agg(\n",
    "        pl.col(\"PassengerId\").count().alias(\"count\")\n",
    "    )\n",
    "    .collect(streaming = True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d933e3a5-d2c8-45cb-962c-19a9a2f0f5a8",
   "metadata": {},
   "source": [
    "In the course we look at what queries streaming can be used in (see the Streaming CSV lecture in the I/O section for more detail)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c5867f-bf81-4e82-b34a-11ba17d3fbeb",
   "metadata": {},
   "source": [
    "## Summary\n",
    "This notebook has been a quick overview of the key ideas that make Polars a powerful data analysis tool:\n",
    "- expressions allow us to write complex transformations concisely and run them in parallel\n",
    "- lazy mode allows Polars apply query optimisations that reduce memory usage and computation time\n",
    "- streaming lets us process larger-than-memory datasets with Polars"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
