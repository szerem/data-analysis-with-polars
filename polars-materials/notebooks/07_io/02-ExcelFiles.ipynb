{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "865b117d-6180-4877-86c1-4ee812ce9a03",
   "metadata": {},
   "source": [
    "# Excel files\n",
    "By the end of this lecture you will be able to:\n",
    "- read an Excel worksheet into a `DataFrame`\n",
    "- choose which engine to use when reading `DataFrames`\n",
    "- read multiple Excel worksheets into a `dict`\n",
    "- writing to an Excel worksheet\n",
    "- adding conditional formatting and sparklines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b54799b-e85f-4054-9261-0fc17f387ba3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eda4073-0b8a-413f-8801-721ac5c89d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = \"../data/titanic.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c20e094-8d91-4a26-be52-ee35324b4a28",
   "metadata": {},
   "source": [
    "## Creating an Excel file\n",
    "In this IO section of the course we use the CSV datasets to create datasets in other formats. We write these datasets to a new `data_files` sub-directory of this directory (i.e. 07_io).\n",
    "\n",
    "We first create a simple Excel file with one worksheet from the Titanic CSV file. \n",
    "\n",
    "To write to an Excel file we need to have the XlsxWriter package installed. XlsxWriter should have been installed when you initially created the virtual environment but you can `pip` install it now if you don't have it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330fbac9-bc80-4670-ad55-325fd9aa38ff",
   "metadata": {},
   "source": [
    "We set the path to our CSV file and the Excel file that we will create in a sub-directory\n",
    "\n",
    "To create the path to the Excel file we:\n",
    "- create a `Path` object using the `Path` function from Python's built-in `pathlib` module\n",
    "- call `mkdir` on the `Path` object to create the sub-directory and any parent sub-directories required\n",
    "- create a `Path` object to the new Excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5659be5-9f69-433a-85f7-17ec8391fd20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Specify a directory to hold the excel files as a Path object\n",
    "excel_titanic_dir = Path('data_files/excel/titanic')\n",
    "# Set the file name of the Excel file\n",
    "excelFile = \"titanic.xlsx\"\n",
    "# Create the Titanic sub-directory if it doesn't exist already\n",
    "excel_titanic_dir.mkdir(parents=True,exist_ok=True)\n",
    "# Set the path to the Titanic excel file\n",
    "titanic_excel_path = excel_titanic_dir / excelFile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ad1f5a-9629-4049-8772-62b41e20ec20",
   "metadata": {},
   "source": [
    "We now create the Excel file at this `Path`.\n",
    "\n",
    "We read the CSV into a `DataFrame` and write it to a .xlsx file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4488120e-b449-447e-820b-92ee4dfa5216",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pl.read_csv(csv_file)\n",
    "df.write_excel(titanic_excel_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd90f23b-ab37-4524-bfae-1e87bf82bfd4",
   "metadata": {},
   "source": [
    "We cover writing to Excel in more detail below.\n",
    "\n",
    "## Reading from a spreadsheet\n",
    "In the simplest cases we can just read the first sheet in the file with `pl.read_excel`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba44c4e8-2adf-4440-aea2-5836f81fab26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pl.read_excel(titanic_excel_path)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf6db67-02dd-43a8-bdcf-e08fb9eed9f8",
   "metadata": {},
   "source": [
    "Reading Excel files happens in eager mode only, we cannot do a lazy scan of an Excel file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d308d5b-a175-4a2e-b5aa-5231d2f0e408",
   "metadata": {},
   "source": [
    "### Choosing the engine\n",
    "Polars uses third party libraries to parse the Excel file. The library used to parse the Excel file is called the *engine* in Polars. The current options are:\n",
    "- xlsx2csv (the current default)\n",
    "- openpyxl\n",
    "- pyxlsb (for Excel binary worksbooks only)\n",
    "- calamine\n",
    "\n",
    "\n",
    "To specify the engine you pass the `engine` argument. Here we use the calamine engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247d5810-c38c-47d4-b878-ee1740318729",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_excel(titanic_excel_path,engine=\"calamine\")\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e00cdb-d11f-46b1-b64c-6cdbad97b34f",
   "metadata": {},
   "source": [
    "We look at the two primary engines in more detail \n",
    "#### xlsx2csv\n",
    "This is the current  default (though calamine will likely become the default at some point)\n",
    "When we call `pl.read_excel` with the xlsx2csv engine:\n",
    "- Polars passes the path to the Excel file to the xlsx2csv package \n",
    "- xlsx2csv parses the XML and converts it to a CSV in-memory\n",
    "- Polars parses the CSV with `pl.read_csv`\n",
    "\n",
    "##### Parsing the XML with xlsx2csv\n",
    "We can pass arguments to xlsx2csv to control how it parses the XML. These options include:\n",
    "- specifying the date format with `DATEFORMAT %Y/%m/%d`\n",
    "- specifying the format for floats with `FLOATFORMAT %.15f`\n",
    "- skip empty lines\n",
    "\n",
    "See https://github.com/dilshod/xlsx2csv for the full set of options.\n",
    "\n",
    "We pass these arguments as a `dict` to the `engine_options` argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b89325-21a6-498a-a7fb-deae7d2bdf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    pl.read_excel(\n",
    "        titanic_excel_path,\n",
    "        engine_options =\n",
    "            {\n",
    "                \"skip_empty_lines\": True,\n",
    "            }\n",
    "    )\n",
    "    .head(2)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86260ae-7379-455d-91e8-6c88973d4b2f",
   "metadata": {},
   "source": [
    "Once xlsx2csv has created the CSV we can pass arguments that we would pass to `pl.read_csv`.\n",
    "\n",
    "In this example we rename the first column using `new_columns`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8e94ef-4756-4377-ae99-87d9b0a3ff5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    pl.read_excel(\n",
    "        titanic_excel_path,\n",
    "        read_options =\n",
    "            {\n",
    "                \"new_columns\":[\"Id\"]\n",
    "            }\n",
    "    )\n",
    "    .head(2)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6513ccb-f973-42e1-89ba-ddc623353c8d",
   "metadata": {},
   "source": [
    "### calamine\n",
    "The calamine engine relies on two Rust crates (where crates are the Rust equivalent of Python packages):\n",
    "- calamine which parses the spreadsheet and\n",
    "- fastexcel which converts the data to an Apache Arrow table\n",
    "\n",
    "To use calamine you must also have the fastexcel library installed. If this was not installed when you started the course you can do so now with `pip install fastexcel`. \n",
    "\n",
    "There are (limited) docs about the fastexcel library here: https://pypi.org/project/fastexcel/\n",
    "\n",
    "### Which engine should I use?\n",
    "While xlsx2csv is the current default the calamine engine is often **much faster** than the other options. \n",
    "\n",
    "However, if your data does not load correctly using calamine (e.g. the dtypes are not correctly inferred) then there is more documentation explaining how to manage this with the xlsxcsv engine. Although it may be easier and faster to just read the data into Polars and then fix it in Polars.\n",
    "\n",
    "Overall, try the calamine engine but if you have problems then use xlsx2csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169f917c-5140-4040-8c3a-74f7aa682b92",
   "metadata": {},
   "source": [
    "## Specifying the worksheet\n",
    "We specify the worksheet with either integer id numbers or names.\n",
    "\n",
    "### Specifying with id numbers\n",
    "We specify the sheet by numbers with the `sheet_id` argument.\n",
    "- By default `sheet_id = 1` and Polars reads the first worksheet\n",
    "- If we set `sheet_id = 0` Polars returns all sheets as a `dict` that maps string sheet names to `DataFrames`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ae2b35-18ff-48dd-8235-e90c622c242c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "excelDict = pl.read_excel(titanic_excel_path,sheet_id=0)\n",
    "excelDict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6bd1cc-e68f-4ade-b50a-71cace801ace",
   "metadata": {},
   "source": [
    "### Specifying with sheet name\n",
    "By default there is no `sheet_name` and the `sheet_id = 1` argument controls the behaviour. We can instead specify the sheet by name with the `sheet_name` argument. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ec2a87-0a5c-42c3-9720-a473367ae5e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(\n",
    "    pl.read_excel(\n",
    "        titanic_excel_path,\n",
    "        sheet_name=\"Sheet1\"\n",
    "    )\n",
    "    .head(2)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8046771-645a-4f2f-b1c2-2be03fdaff7e",
   "metadata": {},
   "source": [
    "\n",
    "Parsing the XML in Excel files is always slow - consider converting your data to CSV, Parquet or Arrow formats if possible!\n",
    "\n",
    "## Writing to a spreadsheet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fafb9c-d4fd-4162-9ed7-72e5a51411b1",
   "metadata": {},
   "source": [
    "As we saw above to write a `DataFrame` to Sheet1 of a new .xlsx file we call `write_excel`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c8715d-e678-4ed7-ac15-66eb7b2ad54c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(\n",
    "    df\n",
    "    .write_excel(\n",
    "        titanic_excel_path\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb1536f-0b11-4b93-b2a5-077133669cd3",
   "metadata": {},
   "source": [
    "### Formatting the worksheet\n",
    "We have a lot of control over how the worksheet looks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8e552c-2654-4377-9dbd-646423ec663c",
   "metadata": {},
   "source": [
    "For example we can:\n",
    "- use built-in Excel table styles with the `table_style` argument\n",
    "- pass a `dict` mapping column names to column widths in pixels with `column_widths`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4a5855-c437-4623-b02f-ae1d7b37094b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(\n",
    "    df\n",
    "    .write_excel(\n",
    "        titanic_excel_path,\n",
    "        table_style='Table Style Medium 2',\n",
    "        column_widths = {col:100 for col in df.columns},\n",
    "        column_formats = {'Age':\"0.000\"}\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a002d5-3c0d-4641-9935-89b950b625da",
   "metadata": {},
   "source": [
    "Instead of passing `column_widths` manually we can also use the `autofit` argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6775d0-0d6b-4adb-9535-431fd2eb0335",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df\n",
    "    .write_excel(\n",
    "        titanic_excel_path,\n",
    "        autofit=True\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec4a54f-6993-4603-9c86-155ad0e8d070",
   "metadata": {},
   "source": [
    "### Formatting values\n",
    "We can set individual column formats in a `dict` with the `column_formats`. We use the patterns that are found when you format a column in Excel under the `Custom` option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc59e31-2337-4961-8655-32e2187bda1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df\n",
    "    .write_excel(\n",
    "        titanic_excel_path,\n",
    "        table_style='Table Style Medium 2',\n",
    "        column_formats = {'Age':\"0.000\"}\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daef5931-e6d2-4ea6-ba39-595f76ca54dd",
   "metadata": {},
   "source": [
    "To format floats it may be easier to use the `float_precision` argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ce6ca1-1065-46fb-a696-58bfb7159868",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(\n",
    "    df\n",
    "    .write_excel(\n",
    "        titanic_excel_path,\n",
    "        table_style='Table Style Medium 2',\n",
    "        float_precision=4\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4486549f-7ae1-4238-9e1e-73b356075992",
   "metadata": {},
   "source": [
    "### Conditional formatting\n",
    "We can apply conditional formatting using the options allowed by Xlswriter. For example, we can have a bar chart in the `Age` column and a 3-color scale for the `Fare` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40169054-1852-4a57-ae85-e183f4c87ea2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(\n",
    "    df\n",
    "    .write_excel(\n",
    "        titanic_excel_path,\n",
    "        table_style='Table Style Medium 2',\n",
    "        autofit=True,\n",
    "        float_precision=3,\n",
    "        conditional_formats = {'Age':'data_bar','Fare':'3_color_scale'}\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bd2285-52d7-4396-b0de-a4c784e13035",
   "metadata": {},
   "source": [
    "See the Xlswriter docs for more info:https://xlsxwriter.readthedocs.io/working_with_conditional_formats.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a5ace0-c64a-4ec3-abfe-ef4b68a210b2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Sparklines\n",
    "We can add sparklines to give a simple visualisation of trends along a row.\n",
    "\n",
    "In this example we first create a `DataFrame` with statistics for each class along a row. We make sparklines to show how these vary across classes.\n",
    "\n",
    "To get the data in the right format we need to do some reshaping with `melt` and `pivot` first. In the example below I have commented out the `write_excel` part so you can see these transformations. Uncomment the `write_excel` part when you want to write the output to the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2b33db-bb8f-4dac-81e3-f2faa32499c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(\n",
    "    df\n",
    "    .group_by('Pclass')\n",
    "    .agg(\n",
    "        pl.col('Age').mean(),\n",
    "        pl.col('Fare').mean(),\n",
    "        pl.col('Survived').count()\n",
    "    )\n",
    "    .with_columns(index=pl.lit(0))\n",
    "    .melt(id_vars=['Pclass'])\n",
    "    .pivot(index='variable',columns='Pclass',values='value',aggregate_function='first')\n",
    "    .pipe(lambda df: df.select('variable','1','2','3'))\n",
    "    # .write_excel(\n",
    "    #     excel_titanic_dir / 'titanic_groupby.xlsx',\n",
    "    #     table_style='Table Style Medium 2',\n",
    "    #     autofit=True,\n",
    "    #     sparklines={\"trend\": [\"1\",\"2\",\"3\"]}\n",
    "    # )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9224b7-a9a7-49f5-af20-3832d17060d5",
   "metadata": {},
   "source": [
    "Read more about sparklines in the API docs: https://pola-rs.github.io/polars/py-polars/html/reference/api/polars.DataFrame.write_excel.html#polars.DataFrame.write_excel\n",
    "\n",
    "## Exercises\n",
    "In the exercises you will develop your understanding of:\n",
    "- writing to an excel file\n",
    "- adding formatting and sparklines\n",
    "- passing arguments when reading an excel file\n",
    "\n",
    "### Exercise 1\n",
    "Create a `DataFrame` from the NYC taxi extract and write it to an Excel file called `nyc.xlsx`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a71d779-65a7-4ce1-9a96-ae7e8e5c8e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "nyccsv_file = \"../data/nyc_trip_data_1k.csv\"\n",
    "# Make a Path variable to write the \n",
    "nycExcelFile = Path('data_files/excel/nyc')\n",
    "nycExcelFile.mkdir(parents=True,exist_ok=True)\n",
    "(\n",
    "    pl.read_csv(nyccsv_file)\n",
    "    <blank>\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0cb191-25c4-4da2-b761-fdd7b36aac28",
   "metadata": {},
   "source": [
    "Write the `DataFrame` to the same file but with a bar chart in the `trip_distance` column and a colormap in the `tip_amount` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949493b2-3389-452e-bcfb-8165349323be",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    pl.read_csv(nyccsv_file)\n",
    "    .write_excel(\n",
    "        <blank>\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02b35eb-fd8c-40cd-8073-a240ffbf72d0",
   "metadata": {},
   "source": [
    "Create a `DataFrame` by reading from the `nyc.xlsx` file with the date columns automatically parsed as datetime dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f6b22a-5446-48f2-be3b-6899fd579d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    pl.read_excel(\n",
    "            nycExcelFile / 'nyc.xlsx',\n",
    "        <blank>\n",
    "    )\n",
    "    .head()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d598c9a7-83f5-4064-a9eb-fb3e7e34222d",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "Get the average of all the floating point columns by day of the week of `pickup` (hint use `.dt.weekday` in the `groupby` expression). Sort the output by the day of the week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c997e0-43ae-4777-b8d9-f11c1d8be644",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    pl.read_csv(nyccsv_file,try_parse_dates=True)\n",
    "    <blank>\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ab079b-ad88-4c75-8471-0d6d628f6547",
   "metadata": {},
   "source": [
    "Reshape the output so that there is one column of variable names and a column for each day of the week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0851af49-2e3e-49e6-902a-e5ed68e7df2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91184188-e72a-469a-addb-d29b1440a79e",
   "metadata": {},
   "source": [
    "Write the reshaped output to an excel file called `nyc_day_of_week.xlsx` in the same directory as above. Add sparklines to show the trend across the days of the week. Ensure the `variable` column is wide enough to be fully legible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164da3b1-b4ef-4ea0-8028-8e6f1b0bb23e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9328a5e1-1404-4cc6-8236-38ead2bce364",
   "metadata": {},
   "source": [
    "## Solutions\n",
    "\n",
    "### Solution to Exercise 1\n",
    "Create a `DataFrame` from the NYC taxi extract and write it to an Excel file called `nyc.xlsx`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04aa2fcf-d7d8-4b5b-89d6-032d86b1b648",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nyccsv_file = \"../data/nyc_trip_data_1k.csv\"\n",
    "# Make a Path variable to write the \n",
    "nycExcelFile = Path('data_files/excel/nyc')\n",
    "nycExcelFile.mkdir(parents=True,exist_ok=True)\n",
    "(\n",
    "    pl.read_csv(nyccsv_file)\n",
    "    .write_excel(nycExcelFile / 'nyc.xlsx')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b1b234-492b-4669-b3a5-5a4bbf56531f",
   "metadata": {},
   "source": [
    "Write the `DataFrame` to the same file but with a bar chart in the `trip_distance` column and a colormap in the `tip_amount` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adec5b9-3bb4-4861-99f0-6e9a03804faa",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "(\n",
    "    pl.read_csv(nyccsv_file)\n",
    "    .write_excel(\n",
    "        nycExcelFile / 'nyc.xlsx',\n",
    "        conditional_formats = {'trip_distance':'data_bar','tip_amount':'3_color_scale'}\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4639ce36-cd1f-42b7-8b5c-fd63f9b09739",
   "metadata": {},
   "source": [
    "Create a `DataFrame` from the `nyc.xlsx` file with the date columns automatically parsed as datetime dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e3d28d-3921-4eb5-bde6-f5e87613db34",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "(\n",
    "    pl.read_excel(\n",
    "            nycExcelFile / 'nyc.xlsx',\n",
    "            read_options={\"try_parse_dates\":True}\n",
    "    )\n",
    "    .head()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17f093f-cce4-4792-949a-bf1bffb2505d",
   "metadata": {},
   "source": [
    "### Solution to Exercise 2\n",
    "Get the average of all the floating point columns by day of the week of `pickup` (hint use `.dt.weekday` in the `groupby` expression). Sort the output by the day of the week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ca2422-d202-447f-852f-48a1344f9a46",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "(\n",
    "    pl.read_csv(nyccsv_file,try_parse_dates=True)\n",
    "    .group_by(\n",
    "        pl.col('pickup').dt.weekday()\n",
    "    )\n",
    "    .agg(\n",
    "        pl.col(pl.Float64).mean()\n",
    "    )\n",
    "    .sort(\"pickup\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b27f40-5ca4-47c5-bdb6-e63093b37239",
   "metadata": {},
   "source": [
    "Reshape the output so that there is one column of variable names and a column for each day of the week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a97a6dc-e6ab-4919-82e0-9090469393dc",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "(\n",
    "    pl.read_csv(nyccsv_file,try_parse_dates=True)\n",
    "    .group_by(\n",
    "        pl.col('pickup').dt.weekday()\n",
    "    )\n",
    "    .agg(\n",
    "        pl.col(pl.Float64).mean()\n",
    "    )\n",
    "    .sort(\"pickup\")\n",
    "    .melt(id_vars=\"pickup\")\n",
    "    .pivot(index=\"variable\",columns=\"pickup\",values=\"value\",aggregate_function=\"first\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98b0212-99bb-4cb5-856c-1e1a4f3c0f08",
   "metadata": {},
   "source": [
    "Write the reshaped output to an excel file called `nyc_day_of_week.xlsx` in the same directory as above. Add sparklines to show the trend across the days of the week. Ensure the `variable` column is wide enough to be fully legible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f68ec95-b306-4023-bab3-90973da8f47f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "(\n",
    "    pl.read_csv(nyccsv_file,try_parse_dates=True)\n",
    "    .group_by(\n",
    "        pl.col('pickup').dt.weekday()\n",
    "    )\n",
    "    .agg(\n",
    "        pl.col(pl.Float64).mean()\n",
    "    )\n",
    "    .sort(\"pickup\")\n",
    "    .melt(id_vars=\"pickup\")\n",
    "    .pivot(index=\"variable\",columns=\"pickup\",values=\"value\",aggregate_function=\"first\")\n",
    "    .write_excel(\n",
    "        workbook = nycExcelFile / \"nyc_day_of_week.xlsx\",\n",
    "        sparklines={\"trend\":[str(idx) for idx in range(1,8)]},\n",
    "        column_widths = {'variable':100}\n",
    "    )  \n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
