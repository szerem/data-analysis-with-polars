{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8093b6a5-2db6-4cde-8cc5-caf21f5cfa6c",
   "metadata": {},
   "source": [
    "# CSV files 1: reading a CSV file\n",
    "By the end of this lecture you will be able to:\n",
    "- set the column names when reading a CSV file\n",
    "- specify how to parse a CSV file\n",
    "- specify a dtype schema  when reading a CSV file\n",
    "- modify CPU and memory usage when reading a CSV file\n",
    "\n",
    "Warning: this is a long lecture as we go through the full CSV parsing process!\n",
    "\n",
    "## What is a CSV file?\n",
    "A CSV file is:\n",
    "- a text file that uses a comma (or other delimiter) to separate values\n",
    "- a file where data is ordered in rows rather than columns\n",
    "- a file where the only potential metadata is a header row of column names - no type information for each column is specified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619f72df-7ddd-42d0-b330-9e077cd5b4fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9b40af-0594-4a5b-b008-aa78dce4e101",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "csv_file = \"../data/titanic.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88371f6e-5b61-4268-a1fe-b53847610a45",
   "metadata": {},
   "source": [
    "We read this CSV file as we have read it many times before!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9d6141-fd94-4476-9e51-3bfb0af5be8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pl.read_csv(csv_file)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa30205e-655e-42e1-a40e-5e172885258d",
   "metadata": {},
   "source": [
    "## CSV parsers\n",
    "\n",
    "CSV files are text and so must be parsed to:\n",
    "1. get the column names\n",
    "2. split each row into columns\n",
    "3. infer the dtype of each column\n",
    "\n",
    "Polars has two engines to parse CSV files: \n",
    "- the default Polars parser\n",
    "- the PyArrow parser\n",
    "\n",
    "We can use the PyArrow parser with the `use_pyarrow` argument in `pl.read_csv`.\n",
    "\n",
    "In my experiments the `Polars` built-in parser is faster and I recommend using it unless there is a specific need for PyArrow.\n",
    "\n",
    "## Compressed CSV files\n",
    "Polars can read .gzip compressed CSV files but not .bz compressed CSV files. \n",
    "\n",
    "To read .bz compressed CSV files use the PyArrow parser\n",
    "```python\n",
    "pl.read_csv(csv_file,use_pyarrow = True)`\n",
    "```\n",
    "## Header and column names\n",
    "By default Polars takes the first row of a CSV as the header to set the column names.\n",
    "\n",
    "### No header\n",
    "If the first row is not a header we can set `has_header = False` and the column names are `column_1` etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a494296-b900-4637-a3b4-179bb77d3c2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pl.read_csv(csv_file, has_header=False).head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ed117b-5632-420c-b02d-e1041b63ee2c",
   "metadata": {},
   "source": [
    "### Rename columns\n",
    "We can rename columns immediately after the CSV is parsed with `new_columns`.\n",
    "\n",
    "In this example we rename the first column in lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5c7fbf-92b5-4fd4-b89c-e59c77f70249",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pl.read_csv(csv_file,new_columns=['passengerid']).head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e025d3-d604-449d-9647-96f345614a4f",
   "metadata": {},
   "source": [
    "### Skip rows after the header\n",
    "We skip rows after the header is parsed with `skip_rows_after_header`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffe3ec0-f326-45f7-b051-7bd4afb69855",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pl.read_csv(csv_file,skip_rows_after_header=1).head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6914822c-cf11-4175-8443-d652f4a34653",
   "metadata": {},
   "source": [
    "### Skip rows to the header\n",
    "\n",
    "If the header is on line `N` of the CSV we can set `skip_rows = N - 1`\n",
    "\n",
    "In this example we set line 2 of the CSV as the header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6acfc2-47c8-4ee3-ae32-e5ec18b473b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pl.read_csv(csv_file,skip_rows=1).head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e9e136-9aa0-401a-a430-51d656e0bdb4",
   "metadata": {},
   "source": [
    "If header names are duplicated (as with columns 7 and 8 of this example) Polars adds `_duplicated_0` to the column name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5cf6a8-7353-46b6-ad4d-4b5ed7aeca73",
   "metadata": {},
   "source": [
    "## Parsing CSVs\n",
    "In the following examples we simulate CSV files with Python strings.\n",
    "\n",
    "The newline `\\n` character shows the line breaks in the simulated CSV file\n",
    "\n",
    "The `b` before the start of the string converts the string to bytes so that it can be passed to `pl.read_csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d27113-b46f-4d18-986d-cf7d63b189fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CSV_string = b\"A,B,C\\n0,1,2\\n\"\n",
    "pl.read_csv(CSV_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3400c1e-5ada-49a4-be8f-03e2ea5783d0",
   "metadata": {},
   "source": [
    "### Delimiter\n",
    "Polars assumes the delimiter is a `,`. This can be changed with the `sep` argument.\n",
    "\n",
    "In this example we have a CSV with tab (`\\t`) separated data rather than comma-separated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11cbf0c-2bf6-40f7-addc-c85d5f35201a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tab_CSV_string = b\"A\\tB\\tC\\n0\\t1\\t2\\n\"\n",
    "\n",
    "pl.read_csv(tab_CSV_string,separator=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4ad32c-0943-4cfc-8672-c0acad321f8d",
   "metadata": {},
   "source": [
    "### Comment lines\n",
    "\n",
    "Comment lines that start with a certain character in the CSV are ignored by setting the `comment_prefix`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad52716f-a72b-42fb-bfb8-52fe2baafda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_CSV_string = b\"a,b,c\\n#Comment\\n0,1,2\\n\"\n",
    "pl.read_csv(comment_CSV_string,comment_prefix=\"#\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2889dc84-b01b-40ad-8d33-cdbf8acc413d",
   "metadata": {},
   "source": [
    "### Quotes\n",
    "Quotes in the CSV are indicated with the `quote_char`. \n",
    "\n",
    "In this example we have quotes because a text contains a comma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b78a745-22ed-4af0-a908-01e5bd9a5b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "quote_CSV_string = b'name,age\\n\"Armstrong,Neil\",39\\n'\n",
    "pl.read_csv(quote_CSV_string,quote_char='\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce1d89a-e981-401b-8e7b-d2f5f4b900ea",
   "metadata": {},
   "source": [
    "## Infering the dtypes\n",
    "Polars needs to understand the dtype of each column in the CSV. To do this Polars:\n",
    "- reads the first 100 lines\n",
    "- if a dtype can be inferred it sets the dtype for that column\n",
    "- if a consistent dtype cannot be inferred then a `ComputeError` exception is raised\n",
    "\n",
    "### Number of rows to infer the dtypes\n",
    "We can adjust the number of lines used for type inference.\n",
    "\n",
    "In the Titanic CSV the `Age` column starts off with 57 integers before a decimal value in line 58.\n",
    "\n",
    "If we try to set `infer_schema_length` lower than 58  Polars raises a `ComputeError` because it infers an integer dtype and then encounters a float on line 58 (check this by reducing the value here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2709b3-e29f-4b29-af29-fe77801239aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.read_csv(csv_file,infer_schema_length=58).head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da34e810-0491-49d7-bd9e-1b8fad9bba6f",
   "metadata": {},
   "source": [
    "### Setting the schema\n",
    "We can also define the schema with a `dict` when reading the CSV. \n",
    "\n",
    "In this example we read in integers and floats as 32-bit dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1f9738-cde0-4294-95e5-9b69e51b0fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.read_csv(\n",
    "    csv_file,\n",
    "    schema={\n",
    "        \"PassengerId\": pl.Int32,\n",
    "        \"Survived\": pl.Int32,\n",
    "        \"Pclass\": pl.Int32,\n",
    "        \"Name\": pl.Utf8,\n",
    "        \"Sex\": pl.Utf8,\n",
    "        \"Age\": pl.Float32,\n",
    "        \"SibSp\": pl.Int32,\n",
    "        \"Parch\": pl.Int32,\n",
    "        \"Ticket\": pl.Utf8,\n",
    "        \"Fare\": pl.Float32,\n",
    "        \"Cabin\": pl.Utf8,\n",
    "        \"Embarked\": pl.Utf8,\n",
    "    },\n",
    ").head(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994efd9f-47fa-4948-b071-8271e8b27b56",
   "metadata": {},
   "source": [
    "## Handling mixed types and exceptions\n",
    "In this example we have a CSV file that will raise an exception as the values in the first column are:\n",
    "- `1.0` which looks like a float and \n",
    "- `a` which is a string\n",
    "\n",
    "In this case Polars casts the column to string dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc40e630-0aa0-4ebe-9345-16c66ebea728",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_type_csv_file = \"../data/badCSV.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6d2133-f50d-4218-a23b-b22e6739f7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.read_csv(mixed_type_csv_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1308431d-626f-46a8-944c-988080241b58",
   "metadata": {},
   "source": [
    "### Specifying the dtypes\n",
    "We can control things by specifying the `dtypes` argument. \n",
    "\n",
    "In this example we read columns of integers as: integer, string and float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014b7018-9fae-477b-b022-63cdd8376604",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_string = b\"A,B,C\\n0,1,2\\n0,1,2\\n\"\n",
    "\n",
    "pl.read_csv(CSV_string,dtypes={'B':pl.Utf8,'C':pl.Float32})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4337334-b2dd-48b9-bbd5-80129770e84f",
   "metadata": {},
   "source": [
    "### Ignore errors\n",
    "We can also tell Polars to ignore errors in which case values that cannot be cast to the schema for that column are returned as `null`.\n",
    "\n",
    "In this case we try to make column `A` boolean but have `True` in the first row and `0` in the second row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b19d8f5-4934-4bdf-884e-0c57241b76a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_string = b\"A,B\\nTrue,1\\n0,1\\n\"\n",
    "\n",
    "pl.read_csv(CSV_string,dtypes={'A':pl.Boolean},ignore_errors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850e78f2-6376-431f-b839-86c225767664",
   "metadata": {},
   "source": [
    "## Set values to `null`\n",
    "We might know that there are values in a column that are incorrect.\n",
    "\n",
    "We set the value `2` in `B` to `null` with `null_values`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ee02a9-0495-427e-ac0b-03bc6ae2c60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_string = b\"A,B\\nTrue,1\\n1,2\\n\"\n",
    "\n",
    "pl.read_csv(CSV_string,null_values=\"2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc8d523-d7d2-4ede-8a24-b9329f4d2794",
   "metadata": {},
   "source": [
    "We can also pass a list of strings to `null_values`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cad96f-bd21-4c91-8a98-b9a816667a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_string = b\"A,B\\nTrue,1\\n1,2\\n\"\n",
    "\n",
    "pl.read_csv(CSV_string,null_values=[\"1\",\"2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47330eed-bc10-4e1a-ba02-d332a2fdeb5d",
   "metadata": {},
   "source": [
    "Or specify different values to set as `null` for different columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81cf048-9191-40e5-83cc-1e091c22f5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_string = b\"A,B\\nTrue,1\\n1,2\\n\"\n",
    "\n",
    "pl.read_csv(CSV_string,null_values={\"B\":\"1\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7baebc-9a8f-4a04-914f-2cdce0e8eb08",
   "metadata": {},
   "source": [
    "## Performance of CSV parsing\n",
    "### Number of threads\n",
    "The CSV parser in Polars is multithreaded and uses the same number of threads as there are cores on your computer.\n",
    "\n",
    "We can vary this with the `n_threads` argument. We can use fewer threads to reduce CPU usage or more threads to (potentially) reduce read time.\n",
    "\n",
    "In experiments on my computer (8 cores) with different datasets compared to the default:\n",
    "- reducing `n_threads` to 1 increases time taken by 3x\n",
    "- reducing `n_threads` to 3-4 increases time taken by 30%\n",
    "- increasing `n_threads` to 40 reduces time taken by 30% on some datasets but makes no difference on others\n",
    "\n",
    "Experiment with your own datasets if you want to reduce CPU usage or reduce read time.\n",
    "\n",
    "### Memory usage\n",
    "We can potentially reduce memory usage when reading a large CSV with `low_memory = True`. When reading a large CSV Polars reads the CSV into separate chunks in memory before combining the chunks into a `DataFrame` that is a single chunk in memory.\n",
    "\n",
    "With `low_memory = True` Polars uses a slower non-parallel method of combining the chunks into a `DataFrame` that is a single chunk in memory.\n",
    "\n",
    "If memory is really an issue then it is best to use streaming mode as explored in the working with multiple CSV files lecture later in this Section.\n",
    "\n",
    "## Exercises\n",
    "In the exercises you will develop your understanding of:\n",
    "- setting the column names of a CSV\n",
    "- parsing a CSV\n",
    "- setting the dtypes\n",
    "- modifying the number of threads\n",
    "\n",
    "### Exercise 1\n",
    "In this exercise we want to parse the CSV strings to produce a `DataFrame` equal to the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cdf998-aba8-4d7b-9da0-b22c5a2940a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = pl.DataFrame({\"a\":[1,2],\"b\":[3,4],\"c\":[5,6]})\n",
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc206a1-7942-41c3-a102-1b474c9befe2",
   "metadata": {},
   "source": [
    "Parse the CSV strings in the following cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b84975-a5eb-4769-84c7-b6c995cc3ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_string = b\"Data passed quality control 2020-01-01\\na,b,c\\n1,3,5\\n2,4,6\\n\"\n",
    "pl.read_csv(<blank>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd1d0ce-c504-49bd-8422-ba3ee14715a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "CSV_string = b\"A,B,C\\n1,3,5\\n2,4,6\\n\"\n",
    "pl.read_csv(<blank>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277becfd-180b-43e1-becc-be054ec3a5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whitespace delimiter\n",
    "CSV_string = b\"a b c\\n1 3 5\\n2 4 6\\n\"\n",
    "pl.read_csv(<blank>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23cbcc6-27ab-4237-b7e2-654e3592a91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comment line\n",
    "CSV_string = b\"a,b,c\\n#Data passed quality control 2020-01-01\\n1,3,5\\n2,4,6\\n\"\n",
    "pl.read_csv(<blank>)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d7c7bc-ae67-4687-8c3a-b04edaca5d6b",
   "metadata": {},
   "source": [
    "This time parse the CSV to produce a `DataFrame` with all columns as 64-bit floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7707d42-0fa0-41eb-998d-a8e7f251e019",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_string = b\"a,b,c\\n#Data passed quality control 2020-01-01\\n1,3,5\\n2,4,6\\n\"\n",
    "pl.read_csv(<blank>)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c9ec04-5c98-4b5f-afd8-1a9d2392581c",
   "metadata": {},
   "source": [
    "Find missing data in the CSV and replace with `null`. Ensure columns are not cast to string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2ae520-43ee-4c09-ac19-1eb36d6226f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_string = b\"a,b,c\\n1,3,5\\nNA,4,na\\n\"\n",
    "pl.read_csv(<blank>)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e52c4a3-bd2e-4f6a-a410-07cf3264db2b",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "Parse the NYC taxi CSV with:\n",
    "- the default number of threads,\n",
    "- one thread and\n",
    "- 40 threads\n",
    "to see if it affects performance.\n",
    "\n",
    "(This dataset is too small to see any differences - but try it with your own datasets to see if changing the number of threads affects performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ec8a2a-5c9e-4346-a038-f9ff5c4d4feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nyccsv_file = \"../data/nyc_trip_data_1k.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4d5ce6-0c02-459c-8ced-50401965bf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n1 -r3\n",
    "pl.read_csv(<blank>)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c2db91-088f-47ef-a4ca-07b462f4958f",
   "metadata": {},
   "source": [
    "## Solutions\n",
    "\n",
    "### Solution to exercise 1\n",
    "In this exercise we want to parse the CSV strings to produce a `DataFrame` equal to the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79cf4bd-037b-4af9-8a03-6bd8803d5de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = pl.DataFrame({\"a\":[1,2],\"b\":[3,4],\"c\":[5,6]})\n",
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8763d8c-5691-4402-a7d3-90f207fa27c8",
   "metadata": {},
   "source": [
    "Parse the CSV strings in the following cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41b01f3-7369-47b5-9716-820bc6e3a108",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CSV_string = b\"Data passed quality control 2020-01-01\\na,b,c\\n1,3,5\\n2,4,6\\n\"\n",
    "pl.read_csv(CSV_string,skip_rows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a3721b-7f86-42bd-9dae-ba401fc4af29",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CSV_string = b\"A,B,C\\n1,3,5\\n2,4,6\\n\"\n",
    "pl.read_csv(CSV_string,new_columns=[\"a\",\"b\",\"c\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9f1327-0020-4774-b74b-c2dda04bc37c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CSV_string = b\"a b c\\n1 3 5\\n2 4 6\\n\"\n",
    "pl.read_csv(CSV_string,separator=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fc2852-b77c-45a3-935d-ea922949167c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CSV_string = b\"a,b,c\\n#Data passed quality control 2020-01-01\\n1,3,5\\n2,4,6\\n\"\n",
    "pl.read_csv(CSV_string,comment_prefix=\"#\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2240f42e-977f-4457-b2ac-e99743f44198",
   "metadata": {},
   "source": [
    "This time parse the CSV with all columns as 64-bit floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc24441-ba07-49ea-97db-b4050845216a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CSV_string = b\"a,b,c\\n#Data passed quality control 2020-01-01\\n1,3,5\\n2,4,6\\n\"\n",
    "pl.read_csv(CSV_string,comment_prefix=\"#\",dtypes={\"a\":pl.Float64,\"b\":pl.Float64,\"c\":pl.Float64})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3908d1-2cc5-4703-be94-7e24af7ef9bd",
   "metadata": {},
   "source": [
    "Find missing data and replace with `null`. Ensure columns are not cast to string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d9ad78-de70-4d8d-b21f-cfc56137cdc2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CSV_string = b\"a,b,c\\n1,3,5\\nNA,4,na\\n\"\n",
    "pl.read_csv(CSV_string,null_values={\"a\":\"NA\",\"c\":\"na\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d16e14d-67cb-4bbc-8458-96a723ce4c4b",
   "metadata": {},
   "source": [
    "## Solution to exercise 2\n",
    "Parse the NYC taxi CSV with:\n",
    "- the default number of threads\n",
    "- one thread\n",
    "- 40 threads\n",
    "to see if it affects performance.\n",
    "\n",
    "Then try it with your own datasets to see if it affects performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a1af91-f87f-4584-ac38-834364735968",
   "metadata": {},
   "outputs": [],
   "source": [
    "nyccsv_file = \"../data/nyc_trip_data_1k.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd30356c-6ecc-4b01-904c-e1875151587c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%timeit -n1\n",
    "pl.read_csv(nyccsv_file,n_threads=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8835d011-feb8-4d74-93cd-7f8db7936530",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%timeit -n1\n",
    "pl.read_csv(nyccsv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3439294d-23bd-4bee-a3d0-41c43394c899",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%timeit -n1\n",
    "pl.read_csv(nyccsv_file,n_threads=40)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
