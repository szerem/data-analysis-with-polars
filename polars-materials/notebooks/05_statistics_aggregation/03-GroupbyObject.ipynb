{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66d73ce5-88a7-4ca4-9c65-80efc207bd62",
   "metadata": {},
   "source": [
    "# Groupby-aggregations 1: Key concepts\n",
    "By the end of this lecture you will be able to:\n",
    "- do a group by-aggregation\n",
    "- group by multiple columns\n",
    "- group by expressions\n",
    "- sort group by outputs\n",
    "- use group by in lazy mode and\n",
    "- do fast-track grouping on a sorted column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd02210d-68fd-400f-adcf-65466018167f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4be68cf-20e2-4017-88e8-e85ad7485d42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "csv_file = \"../data/titanic.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233c146a-3a78-42fa-9b9a-d0ec89cfde44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pl.read_csv(csv_file)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9abe40-2216-450f-8b6f-8710ae78e284",
   "metadata": {},
   "source": [
    "## Group-by and aggregation\n",
    "In Polars we can group by a column and aggregate the data in other columns with the `group_by.agg` combination.\n",
    "\n",
    "In this example we group by the passenger class and take the mean of the `Fare` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7701a115-80b7-435f-aba2-97daf6bd7204",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df\n",
    "    .group_by(\"Pclass\")\n",
    "    .agg(\n",
    "        pl.col(\"Fare\").mean().round()\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ccbdb0-3801-4a4d-a901-4bd317c17794",
   "metadata": {},
   "source": [
    "> Why group_by and not groupby? The Polars API aims to be readable and one standard is to split words by `_`\n",
    "\n",
    "Almost everything we do after this will be some variation on this basic pattern of `group_by` and `agg`.\n",
    "\n",
    "Note that we passed an aggregation expression `pl.col(\"Fare\").mean()` inside `agg` to get a single value for each group.\n",
    "\n",
    "Let's see what happens if we don't pass an aggregation expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f14332-0d8c-4267-a601-e49c0add9604",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df\n",
    "    .group_by(\"Pclass\")\n",
    "    .agg(\n",
    "        pl.col(\"Fare\").head(2)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3568f25-e867-462f-8bfd-3a4565ab6aa8",
   "metadata": {},
   "source": [
    "In this case the `Fare` column is a `pl.List` column with all the values for each group on each row\n",
    "\n",
    "\n",
    "## What happens when we run `group_by.agg`?\n",
    "While the full workings are more complicated than this a basic description of the internal flow is that:\n",
    "- when we call `.group_by` Polars creates a `GroupBy` object that catpures the group-by parameters (e.g. the columns to group by) but **does not calculate the groups** until a further method (such as `agg`) is called on it\n",
    "- when we call `agg` on the `GroupBy` object Polars:\n",
    "    - Polars calculates the groups by getting the row indexes for each group\n",
    "    - Polars applies the expressions in `agg` to each group\n",
    "    - Polars joins the outputs of the expressions back to each group to create the output `DataFrame`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef5abb2-784b-4f95-9077-e62e6ad57576",
   "metadata": {},
   "source": [
    "## Grouping by multiple columns\n",
    "We can group by multiple columns by passing a `list` to `group_by` or a comma-separated list of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ebe319-cdea-4063-94ed-16903b9c7027",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df\n",
    "    .group_by(\"Pclass\",\"Survived\")\n",
    "    .agg(\n",
    "        pl.col(\"Fare\").mean()\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08bbdbc-dd43-484d-ada0-5d5d34b3aef6",
   "metadata": {},
   "source": [
    "We can also use expressions inside `group_by` - in fact when we pass column names as strings (as above) Polars converts these to expressions internally.\n",
    "\n",
    "As we can pass expressions to `group_by` we can also group by a transformed column. Here, for example, we group by the `Age` column with values cast to integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc3ac5f-e245-45ec-9083-895207e8335d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df\n",
    "    .group_by(pl.col(\"Age\").cast(pl.Int64))\n",
    "    .agg(\n",
    "        pl.col(\"Fare\").mean()\n",
    "    )\n",
    "    .head()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6602d905-8316-4655-aeaf-441897d115d4",
   "metadata": {},
   "source": [
    "## Ordering of the output\n",
    "We have seen that the output `DataFrame` has a different order each time. This happens because Polars works out the row indexes for the group keys in parallel. This means that Polars:\n",
    "- splits the group columns into chunks (e.g. first 10 rows in one chunk, second 10 rows in another chunk, etc)\n",
    "- finds the row indexes within each chunk on a seperate thread\n",
    "- brings the results from different threads back together\n",
    "\n",
    "As the order the results come back from different threads is random the order of the output `DataFrame` is random\n",
    "\n",
    "We can force the order of the output to match the order the group keys occur in the input with the `maintain_order` argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adb33bb-fb7f-4535-9e30-fecab6606a50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(\n",
    "    df\n",
    "    .group_by(\"Pclass\",maintain_order=True)\n",
    "    .agg(\n",
    "        pl.col(\"Fare\").mean()\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9eef5b2-a3be-477d-8b24-60f1252efb49",
   "metadata": {},
   "source": [
    "The first row is group `3` because the first row of `df` is `3` and so on.\n",
    "\n",
    "Setting maintain_order=True results will affect performance to some extent. We also cannot use the streaming engine for large datasets when `maintain_order=True`.\n",
    "\n",
    "We need to use the `sort` method if we want to set a different sorting of the output groups.\n",
    "\n",
    "I explored the reason for `group_by` (and related methods such as `unique`) not preserving order by default in this blog post:https://www.rhosignal.com/posts/polars-ordering\n",
    "\n",
    "> If you are running unit tests of a `group_by` you generally want to set `maintain_order=True` to get the same output each time it is run. This is the reason why `maintain_order=True` is normally set in the Polars API docs as these examples are run in the Polars test suite.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56e219b-d54a-4816-9879-23c620713541",
   "metadata": {},
   "source": [
    "## Group by in lazy mode\n",
    "A `group_by.agg` in lazy mode works in a very similar way in lazy mode to eager mode. In fact when we do this in eager mode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c4a2f8-0a82-4dfb-bc97-7a2840eb73a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df\n",
    "    .group_by(\"Pclass\")\n",
    "    .agg(\n",
    "        pl.col(\"Fare\").mean()\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1cd66f-122d-4a0e-a5df-5067457abcef",
   "metadata": {},
   "source": [
    "then Polars internally runs it (more-or-less) like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ecf970-f3d3-4228-9ac5-b274b8454c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df\n",
    "    .lazy()\n",
    "    .group_by(\"Pclass\")\n",
    "    .agg(\n",
    "        pl.col(\"Fare\").mean()\n",
    "    )\n",
    "    .collect()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab7d675-dc36-4fdb-acc2-c2ce9d5f60d3",
   "metadata": {},
   "source": [
    "So we should not expect an isolated `group_by.agg` to run any faster in lazy mode than eager mode.\n",
    "\n",
    "With a query that starts from a file with `pl.scan_*` Polars can do projection pushdown by identifying which columns are needed for the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4630cb84-33ab-4f24-8523-7d09831308a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    pl.scan_csv(csv_file)\n",
    "    .group_by(\"Pclass\")\n",
    "    .agg(\n",
    "        pl.col(\"Fare\").mean()\n",
    "    )\n",
    "    .explain()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610e1be4-6526-44cb-842d-8d025dc36d4a",
   "metadata": {},
   "source": [
    "And we see here in the last row of the optimised query plan that only 2 out of 12 columns are read from the CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86379f0c-3e3f-4693-8468-761b4fda5f75",
   "metadata": {},
   "source": [
    "### Streaming groupby on large datasets\n",
    "We can run `group_by` on large datasets - with the default argument of `maintain_order=False`. However, if we set `maintain_order=True` then `group_by` cannot be run for large datasets in streaming mode.\n",
    "\n",
    "To see this note how the `AGGREGATE` part of this query plan moves outside of the ` --- STREAMING` if you change `maintain_order` from `False` (the default) to `True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cd8595-ffc3-4db2-ba5f-ef4ccdadfebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    pl.scan_csv(csv_file)\n",
    "    .group_by(\"Pclass\",maintain_order=False)\n",
    "    .agg(\n",
    "        pl.col(\"PassengerId\").count()\n",
    "    )\n",
    "    .explain(streaming=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecbbbc0-0d3a-4dcc-a5bb-a7b9a6bb5960",
   "metadata": {},
   "source": [
    "## Groupby on a sorted column\n",
    "In the lecture \"Sorting and Fast-track algorithms\" in the Selecting columns and transforming dataframes section we saw how Polars can use fast-track algorithms on sorted columns - if it knows the column is sorted.\n",
    "\n",
    "A fast-track algorithm can also be used if the groupby column is sorted. See Exercise 3 for an example of this (make sure you have done the Sorting and Fast-track algorithms lecture first)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f303005-de03-42ee-ae91-71e454a2942b",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "In the exercises you will develop your understanding of:\n",
    "- doing `group_by.agg` with one or more columns\n",
    "- transforming columns before grouping\n",
    "- aggregating each group\n",
    "- the effect of the fast-track algorithm on a sorted column\n",
    "\n",
    "### Exercises 1\n",
    "Group by the `Pclass` and `Survived` columns and count the number of passengers in each group. Ensure the order is the same as the input order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640c171b-b364-4c28-a9b6-86d4fcf7a241",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(\n",
    "    pl.read_csv(csv_file)\n",
    "    <blank>\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae08549f-a4e4-4668-89ac-e22addac8150",
   "metadata": {},
   "source": [
    "Did people with longer names pay more for their ticket?\n",
    "\n",
    "Group by the number of characters in the `Name` column and get the average `Fare` for each name length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517a9131-bdb4-4d78-9857-6ae6e19c9fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    pl.read_csv(csv_file)\n",
    "    <blank>\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ae54f5-5a12-434a-9c04-63cc9681f3c2",
   "metadata": {},
   "source": [
    "Make a scatter plot of the output with `plot.scatter`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ef3db4-a2fd-4a4a-a8ae-4b835650f3b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8f8091d6-d9dd-4abc-aebc-a61939aad965",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "We create a `DataFrame` from the Spotify data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf34a77-b285-4dbf-b9f1-85c54a7ba41f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pl.Config.set_fmt_str_lengths(100)\n",
    "pl.Config.set_tbl_rows(10)\n",
    "spotify_csv = \"../data/spotify-charts-2017-2021-global-top200.csv.gz\"\n",
    "spotify_df = pl.read_csv(spotify_csv,try_parse_dates=True)\n",
    "spotify_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3366123a-9541-4f96-acfb-5d3dc362e10f",
   "metadata": {},
   "source": [
    "Format the floating point values so that large floating point numbers are seperated by a comma (or your preferred thousand separator). If you have not encountered this before try tab-completing the following cell to find an appropriate method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283e28a3-0b8a-41a9-98e4-998dc7b8ab66",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.Config.set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23935de-1eda-43e3-a1c3-4b100370b569",
   "metadata": {},
   "source": [
    "Group by the `artist` and `title` columns and get the maximum of the other columns. Sort the output with the largest values of streams first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99a2609-1485-47ad-959c-474538b7bef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    spotify_df\n",
    "    <blank>\n",
    "    .head()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d5b732-5b35-4f60-a0c0-21216b9c4da4",
   "metadata": {},
   "source": [
    "It's easy to forget that the max values are not set by the `stream` columns but all come from different rows. For example the max streams value for each of these entries would have been 1 but instead we see the lowest rank for the track in this output\n",
    "\n",
    "Now we ask if collaborations lead to more streams.\n",
    "\n",
    "Group by the number of artists listed in `artist` column and then take the mean of the streams column. Sort by the number of artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd82dea3-adc1-4e29-8d1f-1a535dce6c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    spotify_df\n",
    "    <blank>\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9507a37b-9604-4a3b-add1-8519ea424835",
   "metadata": {},
   "source": [
    "Make a bar chart of the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500e064f-e514-4bd3-8109-31f0e48fce45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "36b0f972-1ba4-4f8a-9e82-ffd968cf4972",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Exercise 3\n",
    "We look at the effect of sorting and the fast-track algorithm on a `group_by` operation.\n",
    "\n",
    "We create a `DataFrame` with an `id` column of integers and a `values` column\n",
    "\n",
    "- The `N` variable sets the number of rows in the `DataFrame`\n",
    "- The `cardinality` sets the number of distinct group keys in the `id` column\n",
    "\n",
    "We begin with a low cardinality and see the effect of increasing the cardinality later in the exercise.\n",
    "\n",
    "We pre-sort the `id`s before creating the `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb49bd9a-5b67-44df-b7c2-66004ca3ec74",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.Config.set_tbl_rows(4)\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "N = 10_000_000\n",
    "cardinality = 10\n",
    "# Create a sorted array of id integers\n",
    "sorted_array = np.sort(np.random.randint(0,cardinality,N))\n",
    "df = (\n",
    "    pl.DataFrame(\n",
    "        {\n",
    "            \"id\":[i for i in sorted_array],\n",
    "            \"values\":np.random.standard_normal(N)\n",
    "        }\n",
    "    )\n",
    ")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a068052c-7f8f-45f5-bcfe-202f969c3f61",
   "metadata": {},
   "source": [
    "Time how long it takes to groupby the `id` column and take the mean of the `values` column without any fast-track algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7884d548-df0f-4ba8-9b09-98e187d3054f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n1 -r3\n",
    "(\n",
    "    df\n",
    "    <blank>\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e059807-0c28-4d8c-8767-82d80a842ab1",
   "metadata": {},
   "source": [
    "Create a new `DataFrame` called `df_sorted` where we tell Polars the `id` column is sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e0d0ef-2674-4c49-b252-d7148de6b798",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted = (\n",
    "    df\n",
    "    <blank>\n",
    ")\n",
    "df_sorted[\"id\"].flags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77de1b98-cae7-4e0c-bb0f-6a0cda199a68",
   "metadata": {},
   "source": [
    "Time how long it takes to groupby the `id` column and take the mean of the `values` column **with** a fast-track algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69107106-3bd3-43a9-bcf3-8d67c7981943",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n1 -r3\n",
    "(\n",
    "    df_sorted\n",
    "    <blank>\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a505a3bf-1089-4c82-9142-6f67e445e94d",
   "metadata": {},
   "source": [
    "Compare the difference between the sorted and non-sorted algorithms when the cardinality of `id` is higher. Try:\n",
    "- `cardinality = 1_000` and \n",
    "- `cardinality = 1_000_000`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f0dcb2-696f-45d0-9522-1eda1c0f3f41",
   "metadata": {},
   "source": [
    "## Solutions\n",
    "\n",
    "### Solutions to Exercise 1\n",
    "Group by the `Pclass` and `Survived` columns and count the number of passengers in each group. Ensure the order is the same as the input order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b6c2fe-c780-4b83-b373-8db44dc9241e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "(\n",
    "    pl.read_csv(csv_file)\n",
    "    .group_by(\"Pclass\",\"Survived\",maintain_order=True)\n",
    "    .agg(\n",
    "        pl.col(\"Age\").len().alias(\"len\")\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4209d4d-3775-42e7-8975-c2ce0af4c0d8",
   "metadata": {},
   "source": [
    "Did people with longer names pay more for their ticket?\n",
    "\n",
    "Group by the number of characters in the `Name` column and get the average `Fare` for each name length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9550a13d-7019-42b3-831f-b7464537467c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "(\n",
    "    pl.read_csv(csv_file)\n",
    "    .group_by(pl.col(\"Name\").str.len_chars())\n",
    "    .agg(pl.col(\"Fare\").mean().round())\n",
    "    .head()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51017d34-8855-41bf-9dc5-ee462600d076",
   "metadata": {},
   "source": [
    "Make a scatter plot of the output with `plot.scatter`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bde2e4-c5fa-4a0e-94db-96fa634e8d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    pl.read_csv(csv_file)\n",
    "    .group_by(pl.col(\"Name\").str.len_chars())\n",
    "    .agg(pl.col(\"Fare\").mean())\n",
    "    .plot\n",
    "    .scatter(\n",
    "        x=\"Name\",\n",
    "        y=\"Fare\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e06673-41c3-4caf-ad0c-3df1ed7bc916",
   "metadata": {},
   "source": [
    "Overall there is a loose positive relationship between name length and fare paid!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b91dc06-279d-4cd5-9a82-4a269a08ee1e",
   "metadata": {},
   "source": [
    "### Solutions to Exercise 2\n",
    "We create a `DataFrame` from the Spotify data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f5164d-bc73-4c1e-a21a-613d7e5a0a3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pl.Config.set_fmt_str_lengths(100)\n",
    "pl.Config.set_tbl_rows(10)\n",
    "spotify_csv = \"../data/spotify-charts-2017-2021-global-top200.csv.gz\"\n",
    "spotify_df = pl.read_csv(spotify_csv,try_parse_dates=True)\n",
    "spotify_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989dc69c-354a-4143-8a1e-f8fcd58e9cfb",
   "metadata": {},
   "source": [
    "Format the floating point values so that large floating point numbers are seperated by a comma (or your preferred thousand separator). If you have not encountered this before try tab-completing the following cell to find an appropriate method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0e6e84-9dc0-4d11-b800-321553f6aa93",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.Config.set_thousands_separator(\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0d2333-de73-456f-88c4-6da0fed01064",
   "metadata": {},
   "source": [
    "Group by the `artist` and `title` columns and get the maximum of the other columns. Sort the output with the largest values of streams first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac275b8-469c-43f9-9ddc-eebc8e8ea5d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(\n",
    "    spotify_df\n",
    "    .group_by(\"artist\",\"title\")\n",
    "    .agg(\n",
    "        pl.all().max()\n",
    "    )\n",
    "    .sort(\"streams\",descending=True)\n",
    "    .head()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb9569d-9e5c-4652-9570-b46b82dceebd",
   "metadata": {},
   "source": [
    "Now we ask if collaborations lead to more streams.\n",
    "\n",
    "Group by the number of artists listed in `artist` column and then take the mean of the streams column. Sort by the number of artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0541b44-f30a-4bf5-956a-eaa184d06dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    spotify_df\n",
    "    .group_by(number_of_artists = pl.col(\"artist\").str.split(\",\").list.len())\n",
    "    .agg(\n",
    "        pl.col(\"streams\").mean()\n",
    "    )\n",
    "    .sort(\"number_of_artists\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb56c7be-7e3b-4e2b-9abb-7bb4ca1c793e",
   "metadata": {},
   "source": [
    "Make a bar chart of the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556a5070-287c-49e6-b305-ba1f3776fe35",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    spotify_df\n",
    "    .group_by(number_of_artists = pl.col(\"artist\").str.split(\",\").list.len())\n",
    "    .agg(\n",
    "        pl.col(\"streams\").mean()\n",
    "    )\n",
    "    .sort(\"number_of_artists\")\n",
    "    .plot\n",
    "    .bar(\n",
    "        y=\"streams\",\n",
    "        x=\"number_of_artists\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4ebf71-c509-430c-9f31-5b2bcedbb4dd",
   "metadata": {},
   "source": [
    "### Solution to exercise 3\n",
    "We look at the effect of sorting on the performance of a `groupby` operation.\n",
    "\n",
    "We create a `DataFrame` with an `id` column of integers and a `values` column\n",
    "\n",
    "- The `N` variable sets the number of rows in the `DataFrame`\n",
    "- The `cardinality` sets the number of distinct `id`s\n",
    "\n",
    "We pre-sort the `id`s before creating the `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c621b6-eecf-4e97-aaa8-34f453f54155",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.Config.set_tbl_rows(4)\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "# Number of rows\n",
    "N = 10_000_000\n",
    "# Number of unique values in groupby column\n",
    "cardinality = 10\n",
    "# Create a sorted array of id integers\n",
    "sorted_array = np.sort(np.random.randint(0,cardinality,N))\n",
    "# Create a DataFrame from this data\n",
    "df = (\n",
    "    pl.DataFrame(\n",
    "        {\n",
    "            \"id\":[i for i in sorted_array],\n",
    "            \"values\":np.random.standard_normal(N)\n",
    "        }\n",
    "    )\n",
    ")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c181fa-f1c2-4434-a6b6-8287dce62dc8",
   "metadata": {},
   "source": [
    "At this point **we know** that `id` is sorted, but Polars does not"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3cf474-1379-4384-8e1b-43ab29699e01",
   "metadata": {},
   "source": [
    "Time how long it takes to groupby the `id` column and take the mean of the `values` column without any fast-track algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1621b9-21b8-48f6-ac81-b7316a271a5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%timeit -n1 -r3\n",
    "(\n",
    "    df\n",
    "    .group_by(\"id\")\n",
    "    .agg(\n",
    "        pl.col(\"values\").mean()\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624da374-f00d-4232-a411-d4c3688972fb",
   "metadata": {},
   "source": [
    "Create a new `DataFrame` called `df_sorted` where we tell Polars the `id` column is sorted. Check that Polars knows the `id` column is sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e8526a-dddc-4ec0-90ee-36ff5ec61908",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_sorted = (\n",
    "    df\n",
    "    .with_columns(\n",
    "        pl.col(\"id\").set_sorted()\n",
    "    )\n",
    ")\n",
    "df_sorted[\"id\"].flags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb6c14e-bfbe-403d-b7a5-3baaa8c8180f",
   "metadata": {},
   "source": [
    "Time how long it takes to groupby the `id` column and take the mean of the `values` column **with** a fast-track algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41c27c4-4bf7-4d2b-a6dc-d10caac38643",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%timeit -n1 -r3\n",
    "(\n",
    "    df_sorted\n",
    "    .group_by(\"id\")\n",
    "    .agg(\n",
    "        pl.col(\"values\").mean()\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6f182d-da37-460d-b2a6-2e32c7403a77",
   "metadata": {},
   "source": [
    "Compare the difference in timings between the standard and fast-track algorithm when the cardinality of `id` is higher (e.g. equal to 100,000)\n",
    "\n",
    "\n",
    "The difference is much smaller (and possibly negative) when the cardinality of `id` is high"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
