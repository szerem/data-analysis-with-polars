{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ab313ba-6253-4d32-a2e4-5b5558b16c91",
   "metadata": {},
   "source": [
    "# Groupby 2: Group iteration and aggregations\n",
    "By the end of this lecture you will be able to:\n",
    "- iterate over groups\n",
    "- get group values\n",
    "- do multiple aggregations\n",
    "- apply user-defined functions on aggregations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e894f2-657c-4b47-b6f5-b4da9a50fbd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import polars.selectors as cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995173a7-de94-4202-9b79-ca1bc501d690",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "csv_file = '../data/titanic.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e71fc9-e440-4908-a1d3-ab76c7a6eaeb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pl.read_csv(csv_file)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f99bcb-a13a-422f-bb8e-6f266cbbb4bf",
   "metadata": {},
   "source": [
    "## Iterating over groups\n",
    "We can access the `DataFrame` for each group by looping over a `GroupBy` object.\n",
    "\n",
    "When we do this iteration Polars calculates the row indexes for each group on the first iteration so they can be used for the rest of the loop\n",
    "\n",
    "In this example we print the mean for each group. \n",
    "\n",
    "The group key is a `tuple` even when we are only grouping by one column. For this reason we set the first iteration variable to be a one-element tuple as `(pclass,)` so we can define a variable that matches the column name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcb2ccf-4bdf-4575-bc5a-eb739653e6b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for (pclass,),group_df in df.group_by([\"Pclass\"]):\n",
    "    print(f\"PClass:{pclass}\")\n",
    "    print(group_df.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf7ef2f-96e3-43fe-907f-112adf97442d",
   "metadata": {},
   "source": [
    "When we group by multiple columns we see how having the first element as a `tuple` naturally extends to multiple group keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e73a69-307f-4bd9-b2cf-d6b924139cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (pclass,survived),group_df in df.group_by(\"Pclass\",\"Survived\"):\n",
    "    print(f\"PClass:{pclass},Survived:{survived}\")\n",
    "    print(group_df.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512ed574-274e-4600-af92-7ed304ee2be1",
   "metadata": {},
   "source": [
    "## Group values\n",
    "We use `head` to get the first rows in each group.\n",
    "\n",
    "In this example we return a `DataFrame` with the first 2 rows from each group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf09ad1-feb4-4ba6-bc34-031f8e22fb2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(\n",
    "    df\n",
    "    .group_by(\"Pclass\")\n",
    "    .head(2)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d5434e-af12-4e0a-83ce-139160d775fe",
   "metadata": {},
   "source": [
    "We can also use `tail` to get the last elements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d920fcf8-e7df-4bfe-8a92-84efd889262d",
   "metadata": {},
   "source": [
    "## Calling aggregations directly on `group_by`\n",
    "We can call aggregations on all columns directly on `group_by` without using `agg`\n",
    "\n",
    "In this example, we count the number of rows per group and we get a single column of counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6baee5-def5-4d63-a157-0a37d33e4f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df\n",
    "    .group_by(\"Pclass\")\n",
    "    .len()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74db092f-f058-451e-a674-a3e7bb64081a",
   "metadata": {},
   "source": [
    "The methods we can all on `GroupBy` include:\n",
    " - `first` get the first element of each group\n",
    " - `last` get the last element of each group\n",
    " - `n_unique` get the number of unique elements in each group\n",
    " - `count` get the number of elements in each group\n",
    " - `sum` sum the elements in each group\n",
    " - `min` get the smallest element in each group\n",
    " - `max` get the largest element in each group\n",
    " - `mean` get the average of elements in each group\n",
    " - `median` get the median in each group\n",
    " - `quantile` calculate quantiles in each group\n",
    "\n",
    "We can also call aggregations on a lazy group though not all of the above are supported\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec4f660-e91b-49e3-928c-4ea095ba59f4",
   "metadata": {},
   "source": [
    "## Multiple aggregations on the same columns\n",
    "We can use the `prefix` or `suffix` expressions when we do different aggregations on the same columns.\n",
    "\n",
    "In this example we get the `min` and `max` of the floating point columns grouped by passenger class. We then sort the outputs to have aggregations on the same column together by sorting the column names inside a `pipe` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e92e00-f297-4dfb-a8bf-8c97ba5ed67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_column = \"Pclass\"\n",
    "(\n",
    "    df\n",
    "    .group_by(group_column)\n",
    "    .agg(\n",
    "        pl.col(pl.Float64).min().name.suffix(\"_min\"),\n",
    "        pl.col(pl.Float64).max().name.suffix(\"_max\"),\n",
    "    )\n",
    "    .pipe(\n",
    "        lambda df: df.select([group_column]+sorted(df.columns[1:]))\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f7ed50-409a-467a-8f73-535c68ea15d6",
   "metadata": {},
   "source": [
    "In this example we also see how we can apply the same aggregation to multiple columns by using `pl.col(pl.Float64)`. The same approaches we have seen previously for selecting multiple columns in all work here. For example, we can use selectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b67645-55fc-4426-8e7f-4f8aefe5df6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_column = \"Pclass\"\n",
    "(\n",
    "    df\n",
    "    .group_by(group_column)\n",
    "    .agg(\n",
    "        cs.float().min().name.suffix(\"_min\"),\n",
    "        cs.float().max().name.suffix(\"_max\"),\n",
    "    )\n",
    "    .pipe(\n",
    "        lambda df: df.select([group_column]+sorted(df.columns[1:]))\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbc8baa-b478-4ea8-9dc3-6bb5100c7da9",
   "metadata": {},
   "source": [
    "## User-defined functions on groups\n",
    "We can define user-defined functions on groups with `map_groups`. \n",
    "\n",
    "The input to `map_groups` is the sub-`DataFrame` for each group - similar to the `DataFrames` we got when we iterated over the groups above. \n",
    "\n",
    "The output of `map_groups` must also be a `DataFrame`. Polars then vertically concatenates the output `DataFrame` for each group back into a single `DataFrame`\n",
    "\n",
    "In this simple example we get one row for each group with the maximum value for each column in each group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934c8386-2e88-4472-9923-e90a16e45be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df\n",
    "    .group_by(\"Pclass\")\n",
    "    .map_groups(\n",
    "        lambda group_df: group_df.max()\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8f4d39-802f-4406-9e7b-fc9d250741b2",
   "metadata": {},
   "source": [
    "Here we output a 2-row `DataFrame` and get two rows for each group in the output. We do this for the floating point columns only (and we lose the grouping column `Pclass` when we do so)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54293657-1a6c-4519-95bf-8f9b08f1b320",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df\n",
    "    .group_by(\"Pclass\")\n",
    "    .map_groups(\n",
    "        lambda group_df: group_df.select(pl.col(pl.Float64)).head(2)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9558b1b7-b375-4788-855f-7176267d54b8",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "In the exercises you will develop your understanding of\n",
    "- doing multiple aggregations\n",
    "- iterating over groups\n",
    "\n",
    "### Exercise 1\n",
    "Group by the `Pclass` column. Count the number of passengers in each group without using `agg`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4c7852-76f0-4fc6-8378-9ae4b259e7c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(\n",
    "    pl.read_csv(csv_file)\n",
    "    .<blank>\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e03b96-c6d8-4474-a660-32562fa278e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(\n",
    "    pl.read_csv(csv_file)\n",
    "    <blank>\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093b4a46-48b2-4498-9732-86347a4fda4f",
   "metadata": {},
   "source": [
    "Add a column called `percent` with the percentage of the total passengers in each group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7eeee8-ac24-4295-b923-5ecb42c67c0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc61f94d-42e2-4637-b2af-1100164413b7",
   "metadata": {},
   "source": [
    "Create a bar chart of the `percent` column with the title `% per class\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3b367a-9baf-4876-8ca1-6b036a10ef3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec9174cf-22ca-40b2-b0d3-01f02ad0fdcb",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "Create a `DataFrame` from the Spotify data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a1b876-90ee-4568-b561-8e5791cff4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.Config.set_fmt_str_lengths(100)\n",
    "pl.Config.set_tbl_rows(10)\n",
    "spotify_csv = \"../data/spotify-charts-2017-2021-global-top200.csv.gz\"\n",
    "spotify_df = pl.read_csv(spotify_csv,try_parse_dates=True)\n",
    "spotify_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61e1a40-853f-4d07-994c-3b9a34de0137",
   "metadata": {},
   "source": [
    "We want to inspect some data for the top-streaming artists by printing it out:\n",
    "- filter `spotify_df` to include only rows that had more than 10 million streams\n",
    "- `group_by` the `artist` column\n",
    "- ensure the order of the output is the same each time\n",
    "- print the `artist` key\n",
    "- print the sub-`DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1383b8d-33df-488f-b213-b1bf6c705374",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c9dce3d-9836-41f9-b430-737f96ed4006",
   "metadata": {},
   "source": [
    "Repeat this exercise but in this case grouping by the `artist` and `title` column and printing the artist and title for each group"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfab53cd-112d-4430-af7b-b7bb1d5cc7fc",
   "metadata": {},
   "source": [
    "Find the total number of streams by artist for tracks that are number 1 in the charts. Divide the number of streams by 1 million to make it easier to read and sort from high to low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65d9566-0887-49ab-9092-36fab14fab97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "88651718-592d-4d35-a6cd-267a9c05cd5d",
   "metadata": {},
   "source": [
    "Using one of the methods we can call directly on `group_by` find out how many distinct tracks each artist has. Sort the values from high to low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a9ee16-8c89-4656-8aa1-0c4e2f681cb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa373390-9134-4dbd-9788-441945ff462e",
   "metadata": {},
   "source": [
    "## Solutions\n",
    "\n",
    "### Solution to Exercise 1\n",
    "Group by the `Pclass` column. Count the number of passengers in each group without using `agg`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbe5576-754e-49e7-afdb-b6cffe017434",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "(\n",
    "    pl.read_csv(csv_file)\n",
    "    .group_by(\"Pclass\")\n",
    "    .len()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39713ec6-7649-4b07-8177-aa8b36bd10a8",
   "metadata": {},
   "source": [
    "Add a column called `percent` with the percentage of the total passengers in each group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75c16ca-a90f-4908-a1e1-1b32fe2376c0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "(\n",
    "    pl.read_csv(csv_file)\n",
    "    .group_by(\"Pclass\")\n",
    "    .len()\n",
    "    .with_columns(\n",
    "        (100 * (pl.col(\"len\") / pl.col(\"len\").sum())).alias(\"percent\")\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3564a9-f8bb-4a12-ad4d-feebd3887a25",
   "metadata": {},
   "source": [
    "Create a bar chart of the `percent` column by piping the output to `px.bar` with the title `% per class\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c060e05-70eb-4cf1-b880-a299549fa635",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(\n",
    "    pl.read_csv(csv_file)\n",
    "    .group_by(\"Pclass\")\n",
    "    .len()\n",
    "    .with_columns(\n",
    "        (100 * (pl.col(\"len\") / pl.col(\"len\").sum())).alias(\"percent\")\n",
    "    )\n",
    "    .plot\n",
    "    .bar(\n",
    "        x=\"Pclass\",\n",
    "        y=\"percent\",\n",
    "        title=\"% per class\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb65db9-ba9b-4b05-9654-b7c2a2085729",
   "metadata": {},
   "source": [
    "### Solution to Exercise 2\n",
    "Create a `DataFrame` from the Spotify data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a75b75-4908-465e-9044-2efb57b7352f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.Config.set_fmt_str_lengths(100)\n",
    "pl.Config.set_tbl_rows(10)\n",
    "spotify_csv = \"../data/spotify-charts-2017-2021-global-top200.csv.gz\"\n",
    "spotify_df = pl.read_csv(spotify_csv,try_parse_dates=True)\n",
    "spotify_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd799449-6422-4b3b-9ef7-64c153860b61",
   "metadata": {},
   "source": [
    "We want to inspect some data for the top-streaming artists by printing it out:\n",
    "- filter `spotify_df` to include only rows that had more than 10 million streams\n",
    "- `group_by` the `artist` column\n",
    "- ensure the order of the output is the same each time\n",
    "- print the `artist` key\n",
    "- print the sub-`DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb29cf1-502d-408a-b481-efd5c72c3a61",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for (artist,),artist_df in (\n",
    "    spotify_df\n",
    "    .filter(\n",
    "        pl.col(\"streams\") > 10_000_000,\n",
    "    )\n",
    "    .group_by([\"artist\"],maintain_order=True)\n",
    "):\n",
    "    print(artist)\n",
    "    print(artist_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab60fa25-536e-4404-b0c2-a6af6aeba875",
   "metadata": {},
   "source": [
    "Repeat this exercise but in this case grouping by the `artist` and `title` column and printing the artist and title for each group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5d7a91-8c07-4fbb-aa7f-db9a94b81e91",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "for (artist,title),artist_df in (\n",
    "    spotify_df\n",
    "    .filter(\n",
    "        pl.col(\"streams\") > 10_000_000,\n",
    "    )\n",
    "    .group_by(\"artist\",\"title\",maintain_order=True)\n",
    "):\n",
    "    print(artist,title)\n",
    "    print(artist_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a655610e-d7af-4df7-a1fe-ada0dd3c9798",
   "metadata": {},
   "source": [
    "Find the total number of streams by artist for tracks that are number 1 in the charts. Divide the number of streams by 1 million to make it easier to read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2327190e-4eb9-4ad1-8dc2-2cf52fcbcc77",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "(\n",
    "    spotify_df\n",
    "    .filter(\n",
    "        pl.col(\"rank\")==1\n",
    "    )\n",
    "    .group_by(\n",
    "        \"artist\",\"title\"\n",
    "    )\n",
    "    .sum()\n",
    "    .with_columns(\n",
    "        (pl.col(\"streams\")/1e6)\n",
    "    )\n",
    "    .select(\"artist\",\"title\",\"streams\")\n",
    "    .sort(\"streams\",descending=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298db10a-7bf4-426b-be36-0fa9495fc7b6",
   "metadata": {},
   "source": [
    "Using one of the methods we can call directly on `group_by` find out how many distinct tracks each artist has. Sort the values from high to low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2450d8-49be-4191-b310-e10b9b824726",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "(\n",
    "    spotify_df\n",
    "    .group_by(\"artist\")\n",
    "    .n_unique()\n",
    "    .select(\"artist\",\"title\")\n",
    "    .sort(\"title\",descending=True)\n",
    "    .head()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638a068c-b1ae-466b-a9c0-0c68acc04d4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
